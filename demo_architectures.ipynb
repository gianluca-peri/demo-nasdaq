{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianluca-peri/demo-nasdaq/blob/main/demo_architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8_IxJAthIjQ"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Let's consider a simple signal: a sine wave\n",
        "\n",
        "$$y=\\sin(x)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emy_cLbc5h0b"
      },
      "outputs": [],
      "source": [
        "# Creating 1D time series\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(0, 4*np.pi, 100)\n",
        "y = np.sin(x)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('sin(x)')\n",
        "plt.title('Outr time series (sine wave)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqubQoO96es3"
      },
      "outputs": [],
      "source": [
        "# We can think of it as composed by past and future points\n",
        "\n",
        "x_past = x[:len(x)//2]\n",
        "y_past = y[:len(x)//2:]\n",
        "\n",
        "x_future = x[len(x)//2:]\n",
        "y_future = y[len(x)//2:]\n",
        "\n",
        "plt.scatter(x_past, y_past, color='blue', label='past')\n",
        "plt.scatter(x_future, y_future, color='red', label='future')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('sin(x)')\n",
        "plt.title('Outr time series (sine wave)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQGF8_N07NLb"
      },
      "outputs": [],
      "source": [
        "# We can turn the regression problem into a classification problem\n",
        "\n",
        "delta = 0.5\n",
        "last_known_y = y_past[-1]\n",
        "floor = last_known_y - delta\n",
        "ceiling = last_known_y + delta\n",
        "\n",
        "plt.scatter(x_past, y_past, color='blue', label='past')\n",
        "plt.scatter(x_future, y_future, color='red', label='future')\n",
        "plt.axhline(y=floor, color='orange', linestyle='--', label='floor')\n",
        "plt.axhline(y=ceiling, color='green', linestyle='--', label='ceiling')\n",
        "plt.axhline(y=last_known_y, color='black', linestyle='--', label='current value')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('sin(x)')\n",
        "plt.title('Outr time series (sine wave)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoijAo_Bh6vK"
      },
      "source": [
        "# Creating the data for real\n",
        "\n",
        "We can consider our sine signal under a noisy channel:\n",
        "\n",
        "$$y=\\sin(x)+\\eta$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-Z1N2Eo9l6M"
      },
      "outputs": [],
      "source": [
        "# Given a time series (past and future) and a delta we can divide into 3 classes:\n",
        "# Goes up, goes down, and stay (in the middle)\n",
        "\n",
        "def classify_time_series(y_past, y_future, delta, verbose=False):\n",
        "    last_known_y = y_past[-1]\n",
        "    floor = last_known_y - delta\n",
        "    ceiling = last_known_y + delta\n",
        "\n",
        "    if verbose:\n",
        "      print(f'Last known value: {last_known_y}')\n",
        "      print(f'Delta: {delta}')\n",
        "      print(f'Floor: {floor}')\n",
        "      print(f'Ceiling: {ceiling}\\n')\n",
        "\n",
        "    for point in y_future:\n",
        "      if point > ceiling:\n",
        "        return \"goes up\"\n",
        "      elif point < floor:\n",
        "        return \"goes down\"\n",
        "\n",
        "    return \"neutral\"\n",
        "\n",
        "print(classify_time_series(y_past, y_future, delta, verbose=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGou-C1m_9oM"
      },
      "outputs": [],
      "source": [
        "# Suppose we have a really big historical time series (with noise)\n",
        "\n",
        "NOISE_STD_DEV = 0.1\n",
        "\n",
        "lenght_of_time_series = 3000\n",
        "x = np.linspace(0, 96*np.pi, lenght_of_time_series)\n",
        "y = np.sin(x) + np.random.normal(0, NOISE_STD_DEV, len(x))\n",
        "\n",
        "plt.figure(figsize=(24, 6))\n",
        "plt.plot(x, np.sin(x), color='red', label='sine wave')\n",
        "plt.scatter(x, y, label='historical time series')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Our historical time series (sine wave)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtFl-2_hjKYk"
      },
      "source": [
        "# Turn the data into train, validation, and test datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEsxrU36BE9a"
      },
      "outputs": [],
      "source": [
        "# We can use this, with pytorch, to create a custom dataset for classification\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SineWaveDataset(Dataset):\n",
        "  def __init__(self, time_series, input_len, future_lookup_len, delta):\n",
        "\n",
        "    self.time_series = time_series\n",
        "    self.input_len = input_len\n",
        "    self.future_lookup_len = future_lookup_len\n",
        "    self.delta = delta\n",
        "\n",
        "    self.lenght_of_time_series = len(time_series['x'])\n",
        "    self.slices = []\n",
        "\n",
        "    for i in range(self.lenght_of_time_series - input_len - future_lookup_len):\n",
        "      self.slices.append({\n",
        "          'x': time_series['x'][i:i+input_len+future_lookup_len],\n",
        "          'y': time_series['y'][i:i+input_len+future_lookup_len]\n",
        "      })\n",
        "\n",
        "  def classify_time_series(self, y_past, y_future):\n",
        "    last_known_y = y_past[-1]\n",
        "    floor = last_known_y - self.delta\n",
        "    ceiling = last_known_y + self.delta\n",
        "\n",
        "    for point in y_future:\n",
        "      if point > ceiling:\n",
        "        # goes up\n",
        "        return torch.tensor(0)\n",
        "      elif point < floor:\n",
        "        # goes down\n",
        "        return torch.tensor(1)\n",
        "\n",
        "    # neutral\n",
        "    return torch.tensor(2)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.slices)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    current_slice = self.slices[idx]\n",
        "    y_past = current_slice['y'][:self.input_len]\n",
        "    y_future = current_slice['y'][self.input_len:]\n",
        "\n",
        "    input_features_vector = torch.Tensor(y_past)\n",
        "    correct_output = self.classify_time_series(y_past, y_future)\n",
        "\n",
        "    return input_features_vector, correct_output\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "time_series = {\n",
        "    'x': x,\n",
        "    'y': y\n",
        "}\n",
        "\n",
        "TIME_DELTA_IN_DATAPOINTS = 10\n",
        "DELTA = 0.5\n",
        "\n",
        "dataset = SineWaveDataset(\n",
        "    time_series,\n",
        "    input_len=TIME_DELTA_IN_DATAPOINTS,\n",
        "    future_lookup_len=TIME_DELTA_IN_DATAPOINTS,\n",
        "    delta=DELTA\n",
        "    )\n",
        "\n",
        "# Example: print feature vector and correct output\n",
        "\n",
        "print(f'Lenght of dataset: {len(dataset)}')\n",
        "\n",
        "number_of_goes_up_classes = 0\n",
        "number_of_goes_down_classes = 0\n",
        "number_of_neutral_classes = 0\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "  input_features_vector, correct_output = dataset[i]\n",
        "  if correct_output == 0:\n",
        "    number_of_goes_up_classes += 1\n",
        "  elif correct_output == 1:\n",
        "    number_of_goes_down_classes += 1\n",
        "  elif correct_output == 2:\n",
        "    number_of_neutral_classes += 1\n",
        "  else:\n",
        "    raise Exception('Unknown class')\n",
        "\n",
        "print(f'Number of goes up classes: {number_of_goes_up_classes}')\n",
        "print(f'Number of goes down classes: {number_of_goes_down_classes}')\n",
        "print(f'Number of neutral classes: {number_of_neutral_classes}')\n",
        "\n",
        "print('Example:')\n",
        "\n",
        "input_features_vector, correct_output = dataset[0]\n",
        "\n",
        "print('Input features vector:', input_features_vector)\n",
        "print('Correct output:', correct_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtrbSBvr-HiK"
      },
      "outputs": [],
      "source": [
        "# Plot examples of the custom dataset\n",
        "\n",
        "fig, ax = plt.subplots(2, 3, figsize=(20,10))\n",
        "\n",
        "for i in range(2):\n",
        "  for j in range(3):\n",
        "    k = np.random.randint(0, len(dataset))\n",
        "    x_slice = dataset.slices[k]['x']\n",
        "    y_slice = dataset.slices[k]['y']\n",
        "    x_past = x_slice[:TIME_DELTA_IN_DATAPOINTS]\n",
        "    y_past = y_slice[:TIME_DELTA_IN_DATAPOINTS]\n",
        "    x_future = x_slice[TIME_DELTA_IN_DATAPOINTS:]\n",
        "    y_future = y_slice[TIME_DELTA_IN_DATAPOINTS:]\n",
        "    last_known_y = y_past[-1]\n",
        "    floor = last_known_y - DELTA\n",
        "    ceiling = last_known_y + DELTA\n",
        "    ax[i][j].scatter(x_past, y_past, color='blue', label='past')\n",
        "    ax[i][j].scatter(x_future, y_future, color='red', label='future')\n",
        "    ax[i][j].axhline(y=0, color='black', linestyle='-', label='current value')\n",
        "    ax[i][j].axhline(y=last_known_y, color='black', linestyle='--', label='current value')\n",
        "    ax[i][j].axhline(y=floor, color='orange', linestyle='--', label='floor')\n",
        "    ax[i][j].axhline(y=ceiling, color='green', linestyle='--', label='ceiling')\n",
        "    ax[i][j].legend()\n",
        "    ax[i][j].set_xlabel('x')\n",
        "    ax[i][j].set_ylabel('y')\n",
        "    ax[i][j].set_title('Our historical time series (sine wave)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8yIUka1OrLz"
      },
      "outputs": [],
      "source": [
        "# Split into train and test\n",
        "\n",
        "train_frac = 0.6\n",
        "validation_frac = 0.2\n",
        "test_frac = 0.2\n",
        "\n",
        "train_size = int(lenght_of_time_series * train_frac)\n",
        "validation_size = int(lenght_of_time_series * validation_frac)\n",
        "test_size = int(lenght_of_time_series * test_frac)\n",
        "\n",
        "print(f'Train size: {train_size}')\n",
        "print(f'Validation size: {validation_size}')\n",
        "print(f'Test size: {test_size}')\n",
        "\n",
        "train_time_series = {\n",
        "    'x': x[:train_size],\n",
        "    'y': y[:train_size]\n",
        "}\n",
        "\n",
        "validation_time_series = {\n",
        "    'x': x[train_size:train_size+validation_size],\n",
        "    'y': y[train_size:train_size+validation_size]\n",
        "}\n",
        "\n",
        "test_time_series = {\n",
        "    'x': x[train_size+validation_size:],\n",
        "    'y': y[train_size+validation_size:]\n",
        "}\n",
        "\n",
        "# Plot train, validation, and test\n",
        "\n",
        "plt.figure(figsize=(24, 6))\n",
        "plt.plot(x, np.sin(x), color='red', label='sine wave')\n",
        "plt.scatter(train_time_series['x'], train_time_series['y'], label='train')\n",
        "plt.scatter(validation_time_series['x'], validation_time_series['y'], label='validation')\n",
        "plt.scatter(test_time_series['x'], test_time_series['y'], label='test')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Our historical time series (sine wave)')\n",
        "plt.show()\n",
        "\n",
        "# Build the datasets\n",
        "\n",
        "train_dataset = SineWaveDataset(train_time_series, TIME_DELTA_IN_DATAPOINTS, TIME_DELTA_IN_DATAPOINTS, DELTA)\n",
        "validation_dataset = SineWaveDataset(validation_time_series, TIME_DELTA_IN_DATAPOINTS, TIME_DELTA_IN_DATAPOINTS, DELTA)\n",
        "test_dataset = SineWaveDataset(test_time_series, TIME_DELTA_IN_DATAPOINTS, TIME_DELTA_IN_DATAPOINTS, DELTA)\n",
        "\n",
        "print(f'Lenght of train dataset: {len(train_dataset)}')\n",
        "print(f'Lenght of validation dataset: {len(validation_dataset)}')\n",
        "print(f'Lenght of test dataset: {len(test_dataset)}')\n",
        "\n",
        "# Build the dataloaders\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw4qcy4kjl5s"
      },
      "source": [
        "# Train and test a simple MLP\n",
        "\n",
        "This is a basic neural network, that needs fixed input lenght of course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMQy6Xa3uk8J"
      },
      "outputs": [],
      "source": [
        "!pip3 install torchview 1> /dev/null 2> /dev/null\n",
        "from torchview import draw_graph\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Now we can try to classify using a simple MLP\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# MLP definition\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.sequential = torch.nn.Sequential(\n",
        "        torch.nn.Linear(input_size, hidden_size),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(hidden_size, output_size),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.sequential(x)\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "input_size = TIME_DELTA_IN_DATAPOINTS\n",
        "hidden_size = 3000\n",
        "output_size = 3\n",
        "\n",
        "model = MLP(input_size, hidden_size, output_size)\n",
        "\n",
        "# Visualize the network\n",
        "\n",
        "graph = draw_graph(model, input_size=(1, input_size))\n",
        "\n",
        "# Render to PNG file\n",
        "output_path = \"model_graph\"\n",
        "graph.visual_graph.render(filename=output_path, format=\"png\", cleanup=True)\n",
        "\n",
        "# Load the image and display with matplotlib\n",
        "img = mpimg.imread(f\"{output_path}.png\")\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHT0VU0VFd0h"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "losses_train = []\n",
        "losses_validation = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  total_loss = 0\n",
        "  model.train()\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_features_vector)\n",
        "    loss = loss_fn(output, label)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  losses_train.append(total_loss/len(train_dataloader))\n",
        "\n",
        "  # Check validation\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(validation_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    loss = loss_fn(output, label)\n",
        "    total_loss += loss.item()\n",
        "  losses_validation.append(total_loss/len(validation_dataloader))\n",
        "\n",
        "# Making a plot of loss vs epochs\n",
        "\n",
        "plt.plot(losses_train, label='train')\n",
        "plt.plot(losses_validation, label='validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Understand standard shape of model output\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    print(output.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "2c-WhnlRKEyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model to get the train accuracy\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.argmax(output[i]) == label[i]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on train: {correct/total}')\n"
      ],
      "metadata": {
        "id": "r0srb1N_JxXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87uD8ZHkwfBz"
      },
      "outputs": [],
      "source": [
        "# Test the model to get the accuracy\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(test_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.argmax(output[i]) == label[i]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on test: {correct/total}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVhzlbDYmYi5"
      },
      "outputs": [],
      "source": [
        "# Test again with a confidence level\n",
        "\n",
        "confidence = 0.8\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "wrong = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(test_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.max(output[i]) >= confidence:\n",
        "        if torch.argmax(output[i]) == label[i]:\n",
        "          correct += 1\n",
        "        else:\n",
        "          wrong += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on test with confidence {confidence}: {correct/(correct+wrong)}')\n",
        "print(f'Activity on test with confidence {confidence}: {(correct+wrong)/total}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzjnySYU-4i_"
      },
      "source": [
        "# Let's train and test again, but with a RNN\n",
        "\n",
        "This will be a recurrent neural network. The main advantage is that it is able to handle sequences with different lenghts.\n",
        "\n",
        "One of the main points is that we do not need this advantage for our task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtmyH2xh_DfT"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.rnn = torch.nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True, nonlinearity='relu')\n",
        "\n",
        "    self.sequential = torch.nn.Sequential(\n",
        "        torch.nn.Linear(hidden_size, output_size),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.unsqueeze(-1)\n",
        "    h_t, h_f = self.rnn(x)\n",
        "    x = h_f[-1]\n",
        "    x = self.sequential(x)\n",
        "    return x\n",
        "\n",
        "# Notice that an rnn is adaptable to any input size\n",
        "# so imput_size in this case is the dimension of the feature vector (=1)\n",
        "model = RNN(input_size=1, hidden_size=300, output_size=output_size)\n",
        "\n",
        "# Visualize the network\n",
        "\n",
        "# To visualize the data lets use the actual size of the time series (input_size)\n",
        "graph = draw_graph(model, input_size=(1, input_size))\n",
        "\n",
        "# Render to PNG file\n",
        "output_path = \"model_graph\"\n",
        "graph.visual_graph.render(filename=output_path, format=\"png\", cleanup=True)\n",
        "\n",
        "# Load the image and display with matplotlib\n",
        "img = mpimg.imread(f\"{output_path}.png\")\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie-kotJCLNMm"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train and validation\n",
        "\n",
        "losses_train = []\n",
        "losses_validation = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  total_loss = 0\n",
        "  model.train()\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_features_vector)\n",
        "    loss = loss_fn(output, label)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  losses_train.append(total_loss/len(train_dataloader))\n",
        "\n",
        "  # Check validation\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(validation_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    loss = loss_fn(output, label)\n",
        "    total_loss += loss.item()\n",
        "  losses_validation.append(total_loss/len(validation_dataloader))\n",
        "\n",
        "# Make a plot of loss vs epochs\n",
        "\n",
        "plt.plot(losses_train, label='train')\n",
        "plt.plot(losses_validation, label='validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Understand standard shape of model output\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    print(output.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "K_CZ4EIiM8PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model to get the train accuracy\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.argmax(output[i]) == label[i]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on train: {correct/total}')\n"
      ],
      "metadata": {
        "id": "1C8lOMoTNIGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHNDKW4QNP4-"
      },
      "outputs": [],
      "source": [
        "# Test the model to get the accuracy\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(test_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.argmax(output[i]) == label[i]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on test: {correct/total}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs0ewS-BNYGC"
      },
      "outputs": [],
      "source": [
        "# Test again with a confidence level\n",
        "\n",
        "confidence = 0.8\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "wrong = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(test_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.max(output[i]) >= confidence:\n",
        "        if torch.argmax(output[i]) == label[i]:\n",
        "          correct += 1\n",
        "        else:\n",
        "          wrong += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on test with confidence {confidence}: {correct/(correct+wrong)}')\n",
        "print(f'Activity on test with confidence {confidence}: {(correct+wrong)/total}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUQxq-vZl3r0"
      },
      "source": [
        "# Train and test again, but with a CNN\n",
        "\n",
        "This is not able to handle sequences of different lenghts, however it should be able to \"see\" better the shape of the time series."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's do the same thing but with a CNN\n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, kernel_number=16, kernel_size=2, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv_net = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(1, kernel_number, kernel_size, stride, padding),  # [B, 16, L]\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.flattened_size = kernel_number * ((input_size + 2 * padding - kernel_size) // stride + 1)\n",
        "\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.flattened_size, hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # [B, 1, L]\n",
        "        x = self.conv_net(x)         # [B, 16, L]\n",
        "        x = x.view(x.size(0), -1)    # Flatten: [B, 16 * L]\n",
        "        logits = self.fc(x)          # [B, 3]\n",
        "        return logits\n",
        "\n",
        "model = SimpleCNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Visualize the network\n",
        "\n",
        "graph = draw_graph(model, input_size=(1,input_size))\n",
        "\n",
        "# Render to PNG file\n",
        "output_path = \"model_graph\"\n",
        "graph.visual_graph.render(filename=output_path, format=\"png\", cleanup=True)\n",
        "\n",
        "# Load the image and display with matplotlib\n",
        "img = mpimg.imread(f\"{output_path}.png\")\n",
        "plt.figure(figsize=(6,20))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ecYOMbRSWoaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGQgzs2O6Ddo"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train and validation\n",
        "\n",
        "losses_train = []\n",
        "losses_validation = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  total_loss = 0\n",
        "  model.train()\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_features_vector)\n",
        "    loss = loss_fn(output, label)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  losses_train.append(total_loss/len(train_dataloader))\n",
        "\n",
        "  # Check validation\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(validation_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    loss = loss_fn(output, label)\n",
        "    total_loss += loss.item()\n",
        "  losses_validation.append(total_loss/len(validation_dataloader))\n",
        "\n",
        "# Make a plot of loss vs epochs\n",
        "\n",
        "plt.plot(losses_train, label='train')\n",
        "plt.plot(losses_validation, label='validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Understand standard shape of model output\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    print(output.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "UGTVgqQQP7ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model to get the train accuracy\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(train_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.argmax(output[i]) == label[i]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on train: {correct/total}')\n"
      ],
      "metadata": {
        "id": "Gz99Zt1wQABz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNtn0J0sQGBT"
      },
      "outputs": [],
      "source": [
        "# Test the model to get the accuracy\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(test_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.argmax(output[i]) == label[i]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on test: {correct/total}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNvwzUqaQKHj"
      },
      "outputs": [],
      "source": [
        "# Test again with a confidence level\n",
        "\n",
        "confidence = 0.8\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "wrong = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (input_features_vector, label) in enumerate(test_dataloader):\n",
        "    output = model(input_features_vector)\n",
        "    for i in range(len(output)):\n",
        "      if torch.max(output[i]) >= confidence:\n",
        "        if torch.argmax(output[i]) == label[i]:\n",
        "          correct += 1\n",
        "        else:\n",
        "          wrong += 1\n",
        "      total += 1\n",
        "\n",
        "print(f'Accuracy on test with confidence {confidence}: {correct/(correct+wrong)}')\n",
        "print(f'Activity on test with confidence {confidence}: {(correct+wrong)/total}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyl7+TIAuWWY9Xsq8P43jw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}